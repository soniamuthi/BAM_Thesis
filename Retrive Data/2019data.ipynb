{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import cm\n",
    "import fastf1 as ff1\n",
    "from fastf1.core import Laps\n",
    "from fastf1 import utils\n",
    "from fastf1 import plotting\n",
    "plotting.setup_mpl()\n",
    "from timple.timedelta import strftimedelta\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cache_dir = 'Desktop/Thesis/Documents/GitHub/ThesisF1/Cache'\n",
    "\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "ff1.Cache.enable_cache(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule2019 = ff1.get_event_schedule(2019)\n",
    "schedule2020 = ff1.get_event_schedule(2020)\n",
    "schedule2021 = ff1.get_event_schedule(2021)\n",
    "schedule2022 = ff1.get_event_schedule(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Australian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '33', '5', '16', '20', '27', '7', '18', '26', '10', '4', '11', '23', '99', '63', '88', '8', '3', '55']\n",
      "core           INFO \tLoading data for Australian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1415: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  df = pd.concat([df, result], sort=False)\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '5', '33', '16', '8', '20', '4', '7', '11', '27', '3', '23', '99', '26', '18', '10', '55', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_22021/463645302.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_22021/463645302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DriverNumber\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Driver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"raceID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 1, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = \"Australia\"\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[0])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 1, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 1)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"1\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'1': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"1\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '16', '33', '5', '4', '7', '10', '23', '11', '99', '26', '20', '18', '63', '88', '27', '3', '55', '8']\n",
      "core           INFO \tLoading data for Bahrain Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '5', '44', '77', '33', '20', '55', '8', '7', '4', '3', '23', '10', '11', '26', '99', '27', '18', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/380923258.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 2, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][1]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[1])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 2, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 2)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"2\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Chinese Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '5', '33', '16', '10', '3', '11', '7', '23', '8', '18', '20', '55', '99', '63', '88', '4', '26', '27']\n",
      "core           INFO \tLoading data for Chinese Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "core        WARNING \tNo lap data for driver 23\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '5', '16', '33', '10', '3', '27', '20', '8', '26', '11', '7', '55', '4', '18', '63', '88', '23', '99']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/2863793993.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 3, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data = data.drop(data.index[[9]])\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][2]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[2])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 3, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"23\"]\n",
    "data = data[data[\"DriverNumber\"] != \"23\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 3)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"3\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'3': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"3\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '5', '33', '16', '11', '55', '4', '18', '7', '23', '99', '20', '27', '63', '88', '10', '8', '26', '3']\n",
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '5', '33', '11', '26', '4', '99', '16', '55', '3', '23', '20', '18', '8', '27', '63', '88', '7', '10']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/1106078633.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 4, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][3]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[3])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 4, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 4)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"4\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'4': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"4\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Spanish Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '5', '16', '10', '20', '55', '26', '8', '23', '3', '27', '7', '11', '99', '63', '88', '18', '4']\n",
      "core           INFO \tLoading data for Spanish Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '5', '33', '16', '10', '8', '20', '26', '3', '4', '23', '55', '7', '11', '27', '18', '99', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/1396514399.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 5, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][4]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[4])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 5, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 5)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"5\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'5': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"5\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Monaco Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '5', '77', '33', '10', '55', '26', '23', '3', '8', '4', '11', '27', '20', '63', '18', '7', '88', '99', '16']\n",
      "core           INFO \tLoading data for Monaco Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '5', '10', '20', '3', '26', '55', '23', '27', '4', '8', '7', '99', '16', '11', '18', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/3373987612.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 6, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][5]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[5])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 6, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 6)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"6\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'6': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"6\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Canadian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '5', '16', '77', '33', '3', '27', '10', '18', '26', '55', '11', '99', '8', '7', '63', '20', '88', '23', '4']\n",
      "core           INFO \tLoading data for Canadian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['5', '44', '16', '3', '10', '77', '27', '4', '55', '20', '33', '26', '99', '23', '8', '11', '7', '18', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/884026279.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 7, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][6]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[6])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 7, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 7)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"7\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'7': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"7\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for French Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '16', '33', '5', '55', '7', '27', '4', '10', '3', '11', '18', '26', '23', '99', '20', '88', '63', '8']\n",
      "core           INFO \tLoading data for French Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '16', '33', '4', '55', '5', '3', '10', '99', '23', '7', '27', '11', '20', '26', '8', '18', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/1130446294.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 8, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][7]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[7])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 8, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 8)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"8\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'8': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"8\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Austrian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '16', '77', '5', '44', '4', '10', '55', '7', '99', '11', '3', '27', '18', '23', '8', '26', '63', '20', '88']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '44', '33', '77', '20', '4', '7', '99', '10', '5', '8', '27', '23', '3', '55', '11', '18', '26', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/2768281111.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 9, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][8]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[8])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 9, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 9)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"9\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'9': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"9\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for British Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '16', '10', '33', '55', '3', '7', '26', '27', '4', '23', '18', '63', '88', '5', '11', '99', '8', '20']\n",
      "core           INFO \tLoading data for British Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '16', '33', '10', '5', '3', '4', '23', '27', '99', '7', '55', '8', '11', '20', '26', '18', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/981958688.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 10, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][9]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[9])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 10, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 10)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"10\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'10': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"10\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for German Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '5', '26', '18', '55', '23', '8', '20', '44', '88', '63', '7', '99', '10', '77', '27', '16', '4', '3', '11']\n",
      "core           INFO \tLoading data for German Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '77', '10', '7', '8', '55', '11', '27', '16', '99', '20', '3', '26', '18', '4', '23', '63', '88', '5']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/1574610591.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 11, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][10]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[10])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 11, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "aux = pd.DataFrame(aux)\n",
    "aux = aux[aux['DriverNumber'] != \"11\"]\n",
    "data = data[data[\"DriverNumber\"] != \"11\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 11)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"11\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'11': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"11\"\n",
    "all_data = pd.concat([all_data, data])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '5', '16', '55', '10', '7', '77', '4', '23', '11', '27', '20', '3', '26', '63', '18', '99', '88', '8']\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '77', '44', '16', '5', '10', '4', '55', '8', '7', '27', '23', '26', '99', '20', '63', '11', '3', '18', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/1427562093.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 12, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][11]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[11])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 12, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 12)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"12\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'12': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"12\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Belgian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '44', '77', '5', '23', '11', '26', '27', '10', '18', '4', '20', '8', '3', '63', '7', '88', '99', '55', '33']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_last).reset_index(drop=True)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_last).reset_index(drop=True)\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '5', '44', '77', '33', '3', '27', '7', '11', '20', '8', '4', '18', '23', '99', '10', '55', '26', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/1654303296.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 13, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][12]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[12])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 13, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"33\"]\n",
    "data = data[data[\"DriverNumber\"] != \"33\"] \n",
    "aux = aux[aux['DriverNumber'] != \"55\"]\n",
    "data = data[data[\"DriverNumber\"] != \"55\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "\n",
    "# Complete missing data\n",
    "data.loc[data['DriverNumber'] == '88', 'BestQualiTime'] = pd.Timedelta('0 days 00:01:50.838')\n",
    "\n",
    "\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 13)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"13\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'13': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"13\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Italian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '77', '44', '3', '27', '23', '11', '33', '99', '4', '10', '18', '5', '63', '7', '8', '88', '20', '26', '55']\n",
      "core           INFO \tLoading data for Italian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '44', '77', '5', '3', '27', '55', '23', '18', '7', '99', '20', '26', '4', '10', '8', '11', '63', '88', '33']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/544510198.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 14, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][13]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[13])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 14, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 14)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"14\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'14': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"14\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Singapore Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['5', '16', '33', '44', '77', '23', '4', '10', '27', '99', '8', '55', '18', '3', '26', '88', '20', '7', '11', '63']\n",
      "core           INFO \tLoading data for Singapore Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '44', '5', '33', '77', '23', '55', '27', '4', '11', '99', '10', '7', '20', '26', '18', '8', '63', '88', '3']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/3628291155.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 15, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][14]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[14])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 15, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 15)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"15\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'15': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"15\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Russian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '16', '33', '23', '55', '11', '4', '20', '27', '18', '26', '7', '10', '99', '88', '63', '5', '3', '8']\n",
      "core           INFO \tLoading data for Russian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "core        WARNING \tNo lap data for driver 26\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['16', '44', '5', '33', '77', '55', '27', '4', '8', '3', '10', '11', '99', '20', '18', '7', '63', '88', '23', '26']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/1219052619.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 16, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][15]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[15])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 16, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "aux = aux[aux['DriverNumber'] != \"26\"]\n",
    "data = data[data[\"DriverNumber\"] != \"26\"] \n",
    "aux = aux[aux['DriverNumber'] != \"8\"]\n",
    "data = data[data[\"DriverNumber\"] != \"8\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "\n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 16)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"16\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'16': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"16\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Japanese Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '5', '44', '23', '55', '16', '10', '11', '18', '26', '4', '7', '8', '99', '20', '63', '88', '33', '3', '27']\n",
      "core           INFO \tLoading data for Japanese Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['5', '16', '77', '44', '33', '23', '55', '4', '10', '8', '99', '18', '7', '26', '27', '3', '11', '63', '20', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/617298077.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 17, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][16]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[16])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 17, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 17)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"17\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'17': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"17\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Mexican Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '5', '77', '16', '23', '33', '11', '3', '10', '27', '26', '18', '55', '99', '20', '63', '8', '88', '7', '4']\n",
      "core           INFO \tLoading data for Mexican Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '16', '5', '44', '23', '77', '55', '4', '26', '10', '11', '27', '3', '7', '99', '18', '20', '8', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/3443254937.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 18, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][17]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[17])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 18, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 18)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"18\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'18': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"18\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for United States Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '33', '16', '23', '3', '4', '55', '27', '11', '7', '26', '18', '99', '8', '10', '63', '20', '88', '5']\n",
      "core           INFO \tLoading data for United States Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '5', '33', '16', '44', '23', '55', '4', '3', '10', '27', '20', '26', '18', '8', '99', '7', '63', '11', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/4100071514.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 19, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][18]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[18])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 19, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 19)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"19\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'19': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"19\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Brazilian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '10', '55', '7', '99', '3', '44', '4', '11', '26', '20', '63', '8', '23', '27', '88', '5', '16', '18', '77']\n",
      "core           INFO \tLoading data for Brazilian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '5', '44', '16', '77', '23', '10', '8', '7', '20', '4', '3', '99', '27', '11', '26', '18', '63', '88', '55']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/215838718.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 20, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][19]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[19])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 20, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 20)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"20\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'20': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"20\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Abu Dhabi Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '16', '77', '5', '23', '11', '4', '26', '55', '3', '27', '7', '20', '8', '99', '63', '10', '88', '18']\n",
      "core           INFO \tLoading data for Abu Dhabi Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '16', '5', '23', '4', '3', '55', '27', '11', '10', '18', '26', '20', '8', '99', '7', '63', '88']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82539/3887355644.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2019 = ff1.get_session(2019, 21, 'R')\n",
    "race_2019.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2019.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2019.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2019[\"Country\"][20]\n",
    "data[\"Year\"] = 2019\n",
    "dati = schedule2019[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[20])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2019 = ff1.get_session(2019, 21, 'Q')\n",
    "qualification1_2019.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2019.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2019.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2019.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2019) & (races[\"round\"] == 21)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2019.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "wins = pd.read_csv(\"podiums2019.csv\", sep = \";\")\n",
    "wins = wins[[\"Driver\", \"21\"]]\n",
    "\n",
    "data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "data = data.rename(columns={'21': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2019.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2019.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"21\"\n",
    "all_data = pd.concat([all_data, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(r'2019data.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>DriverNumber</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>Position</th>\n",
       "      <th>GridPosition</th>\n",
       "      <th>Status</th>\n",
       "      <th>Points</th>\n",
       "      <th>RaceCountry</th>\n",
       "      <th>Year</th>\n",
       "      <th>AgeAtGP</th>\n",
       "      <th>...</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Driver</th>\n",
       "      <th>AverageSpeed</th>\n",
       "      <th>MaxSpeed</th>\n",
       "      <th>AverageRPM</th>\n",
       "      <th>MaxRPM</th>\n",
       "      <th>AverageThrottle</th>\n",
       "      <th>MaxThrottlePct</th>\n",
       "      <th>Brake</th>\n",
       "      <th>raceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAS</td>\n",
       "      <td>10</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>153.154148</td>\n",
       "      <td>326</td>\n",
       "      <td>7793.417721</td>\n",
       "      <td>12860</td>\n",
       "      <td>49.783810</td>\n",
       "      <td>38.567815</td>\n",
       "      <td>13.413764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PER</td>\n",
       "      <td>11</td>\n",
       "      <td>Racing Point</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>152.749173</td>\n",
       "      <td>331</td>\n",
       "      <td>7973.695239</td>\n",
       "      <td>13252</td>\n",
       "      <td>50.152656</td>\n",
       "      <td>24.220017</td>\n",
       "      <td>14.542388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEC</td>\n",
       "      <td>16</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>155.409580</td>\n",
       "      <td>312</td>\n",
       "      <td>7691.757735</td>\n",
       "      <td>12319</td>\n",
       "      <td>56.245606</td>\n",
       "      <td>3.762081</td>\n",
       "      <td>15.816955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STR</td>\n",
       "      <td>18</td>\n",
       "      <td>Racing Point</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>153.104527</td>\n",
       "      <td>323</td>\n",
       "      <td>7737.558799</td>\n",
       "      <td>13073</td>\n",
       "      <td>49.155575</td>\n",
       "      <td>3.580463</td>\n",
       "      <td>13.238633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAG</td>\n",
       "      <td>20</td>\n",
       "      <td>Haas F1 Team</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>155.144905</td>\n",
       "      <td>314</td>\n",
       "      <td>7912.993287</td>\n",
       "      <td>12771</td>\n",
       "      <td>58.128754</td>\n",
       "      <td>7.825777</td>\n",
       "      <td>20.419018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RAI</td>\n",
       "      <td>7</td>\n",
       "      <td>Alfa Romeo Racing</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UAE</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>139.389846</td>\n",
       "      <td>344</td>\n",
       "      <td>7402.660745</td>\n",
       "      <td>12840</td>\n",
       "      <td>54.256140</td>\n",
       "      <td>8.407731</td>\n",
       "      <td>25.484715</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BOT</td>\n",
       "      <td>77</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Finished</td>\n",
       "      <td>12.0</td>\n",
       "      <td>UAE</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>77</td>\n",
       "      <td>141.719842</td>\n",
       "      <td>339</td>\n",
       "      <td>7583.554604</td>\n",
       "      <td>13233</td>\n",
       "      <td>47.303334</td>\n",
       "      <td>0.937866</td>\n",
       "      <td>16.962756</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GRO</td>\n",
       "      <td>8</td>\n",
       "      <td>Haas F1 Team</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UAE</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>139.600355</td>\n",
       "      <td>341</td>\n",
       "      <td>7576.323053</td>\n",
       "      <td>12822</td>\n",
       "      <td>43.428653</td>\n",
       "      <td>0.399796</td>\n",
       "      <td>16.508853</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KUB</td>\n",
       "      <td>88</td>\n",
       "      <td>Williams</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>+2 Laps</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UAE</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>88</td>\n",
       "      <td>136.879160</td>\n",
       "      <td>327</td>\n",
       "      <td>7442.653200</td>\n",
       "      <td>12633</td>\n",
       "      <td>47.375056</td>\n",
       "      <td>1.908799</td>\n",
       "      <td>17.461749</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GIO</td>\n",
       "      <td>99</td>\n",
       "      <td>Alfa Romeo Racing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>+1 Lap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UAE</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>139.682448</td>\n",
       "      <td>340</td>\n",
       "      <td>7540.465296</td>\n",
       "      <td>12759</td>\n",
       "      <td>52.965281</td>\n",
       "      <td>6.793519</td>\n",
       "      <td>22.962696</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Abbreviation DriverNumber           TeamName  Position  GridPosition  \\\n",
       "0           GAS           10    Red Bull Racing      11.0          17.0   \n",
       "1           PER           11       Racing Point      13.0          10.0   \n",
       "2           LEC           16            Ferrari       5.0           5.0   \n",
       "3           STR           18       Racing Point       9.0          16.0   \n",
       "4           MAG           20       Haas F1 Team       6.0           7.0   \n",
       "..          ...          ...                ...       ...           ...   \n",
       "15          RAI            7  Alfa Romeo Racing      13.0          17.0   \n",
       "16          BOT           77           Mercedes       4.0          20.0   \n",
       "17          GRO            8       Haas F1 Team      15.0          15.0   \n",
       "18          KUB           88           Williams      19.0          19.0   \n",
       "19          GIO           99  Alfa Romeo Racing      16.0          16.0   \n",
       "\n",
       "      Status  Points RaceCountry    Year  AgeAtGP  ...   Rain  Driver  \\\n",
       "0     +1 Lap     0.0   Australia  2019.0     22.0  ...  False      10   \n",
       "1     +1 Lap     0.0   Australia  2019.0     29.0  ...  False      11   \n",
       "2   Finished    10.0   Australia  2019.0     21.0  ...  False      16   \n",
       "3     +1 Lap     2.0   Australia  2019.0     20.0  ...  False      18   \n",
       "4   Finished     8.0   Australia  2019.0     26.0  ...  False      20   \n",
       "..       ...     ...         ...     ...      ...  ...    ...     ...   \n",
       "15    +1 Lap     0.0         UAE  2019.0     40.0  ...  False       7   \n",
       "16  Finished    12.0         UAE  2019.0     30.0  ...  False      77   \n",
       "17    +1 Lap     0.0         UAE  2019.0     33.0  ...  False       8   \n",
       "18   +2 Laps     0.0         UAE  2019.0     35.0  ...  False      88   \n",
       "19    +1 Lap     0.0         UAE  2019.0     25.0  ...  False      99   \n",
       "\n",
       "   AverageSpeed MaxSpeed   AverageRPM MaxRPM  AverageThrottle  MaxThrottlePct  \\\n",
       "0    153.154148      326  7793.417721  12860        49.783810       38.567815   \n",
       "1    152.749173      331  7973.695239  13252        50.152656       24.220017   \n",
       "2    155.409580      312  7691.757735  12319        56.245606        3.762081   \n",
       "3    153.104527      323  7737.558799  13073        49.155575        3.580463   \n",
       "4    155.144905      314  7912.993287  12771        58.128754        7.825777   \n",
       "..          ...      ...          ...    ...              ...             ...   \n",
       "15   139.389846      344  7402.660745  12840        54.256140        8.407731   \n",
       "16   141.719842      339  7583.554604  13233        47.303334        0.937866   \n",
       "17   139.600355      341  7576.323053  12822        43.428653        0.399796   \n",
       "18   136.879160      327  7442.653200  12633        47.375056        1.908799   \n",
       "19   139.682448      340  7540.465296  12759        52.965281        6.793519   \n",
       "\n",
       "        Brake  raceID  \n",
       "0   13.413764       1  \n",
       "1   14.542388       1  \n",
       "2   15.816955       1  \n",
       "3   13.238633       1  \n",
       "4   20.419018       1  \n",
       "..        ...     ...  \n",
       "15  25.484715      21  \n",
       "16  16.962756      21  \n",
       "17  16.508853      21  \n",
       "18  17.461749      21  \n",
       "19  22.962696      21  \n",
       "\n",
       "[414 rows x 34 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no pit stops\n",
    "all_data['AvgPitTime'] = all_data['AvgPitTime'].fillna(pd.Timedelta(\"0 days\"))\n",
    "\n",
    "all_data['PitstopNo'] = all_data['PitstopNo'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing qualification times\n",
    "# VET Germany\n",
    "all_data.loc[(all_data['Abbreviation'] == 'VET') & (all_data['RaceCountry'] == 'Germany'), 'BestQualiTime'] = pd.Timedelta('0 days 00:01:17.285')\n",
    "\n",
    "# MAG Japan\n",
    "all_data.loc[(all_data['Abbreviation'] == 'MAG') & (all_data['RaceCountry'] == 'Japan'), 'BestQualiTime'] = pd.Timedelta('0 days 00:01:34.593')\n",
    "\n",
    "# KUB Japan\n",
    "all_data.loc[(all_data['Abbreviation'] == 'KUB') & (all_data['RaceCountry'] == 'Japan'), 'BestQualiTime'] = pd.Timedelta('0 days 00:01:34.593')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(r'2019data.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5735bfa344102866903967fdbfb95794eb353dada4cd8a6f59858b1fed696402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
