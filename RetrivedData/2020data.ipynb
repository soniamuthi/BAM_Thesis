{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import cm\n",
    "import fastf1 as ff1\n",
    "from fastf1.core import Laps\n",
    "from fastf1 import utils\n",
    "from fastf1 import plotting\n",
    "plotting.setup_mpl()\n",
    "from timple.timedelta import strftimedelta\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cache_dir = 'Desktop/Thesis/Documents/GitHub/ThesisF1/Cache'\n",
    "\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "ff1.Cache.enable_cache(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule2019 = ff1.get_event_schedule(2019)\n",
    "schedule2020 = ff1.get_event_schedule(2020)\n",
    "schedule2021 = ff1.get_event_schedule(2021)\n",
    "schedule2022 = ff1.get_event_schedule(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Austrian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "core        WARNING \tDriver  8: Lap timing integrity check failed for 1 lap(s)\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '16', '4', '44', '55', '11', '10', '31', '99', '5', '6', '26', '23', '7', '63', '8', '20', '18', '3', '33']\n",
      "core           INFO \tLoading data for Austrian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '33', '4', '23', '11', '16', '55', '18', '3', '5', '10', '26', '31', '8', '20', '63', '99', '7', '6']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/2668962785.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 1, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][2]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[2])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 1, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 1)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"22\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Hungarian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 19 drivers: ['44', '33', '77', '18', '23', '5', '11', '3', '55', '20', '16', '26', '4', '7', '8', '99', '63', '6', '10']\n",
      "core           INFO \tLoading data for Hungarian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '18', '11', '5', '16', '33', '4', '55', '10', '3', '63', '23', '31', '6', '20', '26', '8', '99', '7']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/250582590.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 3, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][4]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[4])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 3, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 3)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"23\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for British Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '16', '3', '4', '31', '10', '23', '18', '5', '77', '63', '55', '99', '6', '8', '7', '26', '20', '27']\n",
      "core           INFO \tLoading data for British Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '16', '4', '18', '55', '3', '31', '5', '10', '23', '27', '26', '63', '20', '99', '7', '8', '6']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/884901328.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 4, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][5]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[5])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 4, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    " \n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"20\"]\n",
    "data = data[data[\"DriverNumber\"] != \"20\"] \n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"27\"]\n",
    "data = data[data[\"DriverNumber\"] != \"27\"]\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 4)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"24\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for 70th Anniversary Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '44', '77', '16', '23', '18', '27', '31', '4', '26', '10', '5', '55', '3', '7', '8', '99', '63', '6', '20']\n",
      "core           INFO \tLoading data for 70th Anniversary Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '27', '33', '3', '18', '10', '16', '23', '4', '31', '5', '55', '8', '63', '26', '20', '6', '99', '7']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/3032754211.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 5, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][6]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[6])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 5, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    " \n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 5)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"25\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Spanish Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '77', '18', '11', '55', '5', '23', '10', '4', '3', '26', '31', '7', '20', '99', '63', '6', '8', '16']\n",
      "core           INFO \tLoading data for Spanish Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '11', '18', '23', '55', '4', '16', '10', '5', '26', '3', '7', '31', '20', '8', '63', '6', '99']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/1960488995.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 6, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][7]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[7])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 6, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    " \n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 6)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"26\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Belgian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '3', '31', '23', '4', '10', '18', '11', '26', '7', '5', '16', '8', '6', '20', '99', '63', '55']\n",
      "core           INFO \tLoading data for Belgian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '3', '23', '31', '55', '11', '18', '4', '26', '10', '16', '5', '63', '7', '8', '99', '6', '20']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/285188870.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 7, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][8]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[8])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 7, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"55\"]\n",
    "data = data[data[\"DriverNumber\"] != \"55\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 7)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"27\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Italian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['10', '55', '18', '4', '77', '3', '44', '31', '26', '11', '6', '8', '7', '63', '23', '99', '33', '16', '20', '5']\n",
      "core           INFO \tLoading data for Italian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '55', '11', '33', '4', '3', '18', '23', '10', '26', '31', '16', '7', '20', '8', '5', '99', '63', '6']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/1831649980.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 8, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][9]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[9])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 8, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "#aux = aux[aux['DriverNumber'] != \"55\"]\n",
    "#data = data[data[\"DriverNumber\"] != \"55\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 8)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"28\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Tuscan Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_last).reset_index(drop=True)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_last).reset_index(drop=True)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_last).reset_index(drop=True)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_last).reset_index(drop=True)\n",
      "/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/fastf1/core.py:1411: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_last).reset_index(drop=True)\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '23', '3', '11', '4', '26', '16', '7', '5', '63', '8', '18', '31', '6', '20', '99', '55', '33', '10']\n",
      "core           INFO \tLoading data for Tuscan Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '23', '16', '11', '18', '3', '55', '31', '4', '26', '7', '5', '8', '10', '99', '63', '6', '20']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/345811319.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 9, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][10]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[10])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 9, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"33\"]\n",
    "data = data[data[\"DriverNumber\"] != \"33\"] \n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"10\"]\n",
    "data = data[data[\"DriverNumber\"] != \"10\"]\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 9)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"29\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Russian Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '33', '44', '11', '3', '16', '31', '26', '10', '23', '99', '20', '5', '7', '4', '6', '8', '63', '55', '18']\n",
      "core           INFO \tLoading data for Russian Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '77', '11', '3', '55', '31', '4', '10', '23', '16', '26', '18', '63', '5', '8', '99', '20', '6', '7']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/2794596360.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 10, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][11]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[11])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 10, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"55\"]\n",
    "data = data[data[\"DriverNumber\"] != \"55\"] \n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"18\"]\n",
    "data = data[data[\"DriverNumber\"] != \"18\"]\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 10)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"30\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Eifel Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '3', '11', '55', '10', '16', '27', '8', '99', '5', '7', '20', '6', '26', '4', '23', '31', '77', '63']\n",
      "core           INFO \tLoading data for Eifel Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '33', '16', '23', '3', '31', '4', '11', '55', '5', '10', '26', '99', '20', '8', '63', '6', '7', '27']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/2413480375.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 11, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][12]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[12])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 11, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 11)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"31\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Portuguese Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '16', '10', '55', '11', '31', '3', '5', '7', '23', '4', '63', '99', '20', '8', '6', '26', '18']\n",
      "core           INFO \tLoading data for Portuguese Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '16', '11', '23', '55', '4', '10', '3', '31', '18', '26', '63', '5', '7', '99', '8', '20', '6']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/1842480253.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 12, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][13]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[13])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 12, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 12)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"32\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Emilia Romagna Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '3', '26', '16', '11', '55', '4', '7', '99', '6', '5', '18', '8', '23', '63', '33', '20', '31', '10']\n",
      "core           INFO \tLoading data for Emilia Romagna Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '44', '33', '10', '3', '23', '16', '26', '4', '55', '11', '31', '63', '5', '18', '8', '20', '7', '6', '99']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/1105403336.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 13, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][14]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[14])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 13, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 13)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"33\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Turkish Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '11', '5', '16', '55', '33', '23', '4', '18', '3', '31', '26', '10', '77', '7', '63', '20', '8', '6', '99']\n",
      "core           INFO \tLoading data for Turkish Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['18', '33', '11', '23', '3', '44', '31', '7', '77', '99', '4', '5', '55', '16', '10', '20', '26', '63', '8', '6']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/2911552059.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 14, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][15]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[15])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 14, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 14)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"34\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Bahrain Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '33', '23', '4', '55', '10', '3', '77', '31', '16', '26', '63', '5', '6', '7', '99', '20', '11', '18', '8']\n",
      "core           INFO \tLoading data for Bahrain Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "session     WARNING \tRequest for URL https://ergast.com/api/f1/2020/15/qualifying.json failed; using cached response\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/http/client.py\", line 289, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/requests_cache/session.py\", line 230, in _resend_and_ignore\n",
      "    response = self._send_and_cache(request, actions, cached_response, **kwargs)\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/requests_cache/session.py\", line 189, in _send_and_cache\n",
      "    response = super().send(request, **kwargs)\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/soniamuthi/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py\", line 547, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '77', '33', '23', '11', '3', '31', '10', '4', '26', '5', '16', '18', '63', '55', '99', '7', '20', '8', '6']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/2119323747.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 15, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][16]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[16])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 15, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"8\"]\n",
    "data = data[data[\"DriverNumber\"] != \"8\"] \n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"18\"]\n",
    "data = data[data[\"DriverNumber\"] != \"18\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 15)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"35\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Sakhir Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['11', '31', '18', '55', '3', '23', '26', '77', '63', '4', '10', '5', '99', '7', '20', '89', '51', '6', '33', '16']\n",
      "core           INFO \tLoading data for Sakhir Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['77', '63', '33', '16', '11', '26', '3', '55', '10', '18', '31', '23', '5', '99', '4', '20', '6', '89', '7', '51']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/3903351889.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 16, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][17]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[17])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 16, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"33\"]\n",
    "data = data[data[\"DriverNumber\"] != \"33\"] \n",
    "\n",
    "aux = aux[aux['DriverNumber'] != \"16\"]\n",
    "data = data[data[\"DriverNumber\"] != \"16\"] \n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 16)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"36\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Abu Dhabi Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '77', '44', '23', '4', '55', '3', '10', '31', '18', '26', '7', '16', '5', '63', '99', '6', '20', '51', '11']\n",
      "core           INFO \tLoading data for Abu Dhabi Grand Prix - Qualifying [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n",
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['33', '77', '44', '4', '23', '55', '26', '18', '16', '10', '31', '3', '5', '99', '11', '7', '20', '63', '51', '6']\n",
      "/var/folders/9y/4s11m74116l5jdmj807gjywm0000gn/T/ipykernel_82759/2044410582.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n"
     ]
    }
   ],
   "source": [
    "# Load race data\n",
    "race_2020 = ff1.get_session(2020, 17, 'R')\n",
    "race_2020.load(telemetry = True, laps = True, weather = True)\n",
    "\n",
    "# Create dataframe\n",
    "aux = race_2020.results\n",
    "data = aux[[\"Abbreviation\", \"DriverNumber\", \"TeamName\", \"Position\", \"GridPosition\", \"Status\", \"Points\"]]\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Add driver age at the time of the race\n",
    "birth = pd.read_csv(\"BIRTH2020.csv\", sep = \";\")\n",
    "birth[\"Birth\"] = pd.to_datetime(birth[\"Birth\"], format=\"%d.%m.%Y\")\n",
    "birth.columns = [\"Abbreviation\", \"Birth\"]\n",
    "\n",
    "# Add race country and year\n",
    "data[\"RaceCountry\"] = schedule2020[\"Country\"][18]\n",
    "data[\"Year\"] = 2020\n",
    "dati = schedule2020[\"EventDate\"]\n",
    "data[\"RaceDate\"] = pd.to_datetime(dati[18])\n",
    "#formatted_date = timestamp.strftime('%d.%m.%Y')\n",
    "data = pd.merge(data, birth, on='Abbreviation', how='inner')\n",
    "data['AgeAtGP'] = (data[\"RaceDate\"] - data[\"Birth\"]) // pd.Timedelta(days=365.25)\n",
    "data = data.drop(columns=[\"Birth\", \"RaceDate\"])\n",
    "\n",
    "# Load qualifications data\n",
    "qualification1_2020 = ff1.get_session(2020, 17, 'Q')\n",
    "qualification1_2020.load()\n",
    "\n",
    "# Add the best qualifications lap\n",
    "fastest_laps = qualification1_2020.laps.groupby(\"DriverNumber\")[\"LapTime\"].min()\n",
    "fastest_laps = pd.DataFrame(fastest_laps)\n",
    "fastest_laps[\"DriverNumber\"] = fastest_laps.index\n",
    "fastest_laps = fastest_laps.reset_index(drop=True)\n",
    "data = pd.merge(left=data, right=fastest_laps, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'BestQualiTime'})\n",
    "\n",
    "# Add fastest lap point\n",
    "aux = race_2020.laps.pick_fastest()\n",
    "auxDriverNo = aux[1]\n",
    "data['FLapPoint'] = (data['DriverNumber'] == auxDriverNo).astype(int)\n",
    "\n",
    "# Add average and std dev of lap times\n",
    "aux = race_2020.laps\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi\n",
    "\n",
    "mean_lap_time = auxi.groupby('DriverNumber')['LapTime'].mean()\n",
    "mean_lap_time = pd.DataFrame(mean_lap_time)\n",
    "\n",
    "mean_lap_time[\"DriverNumber\"] = mean_lap_time.index\n",
    "mean_lap_time = mean_lap_time.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=mean_lap_time, how='right')\n",
    "data = data.rename(columns = {'LapTime': 'AvgLapTime'})\n",
    "\n",
    "auxi = aux[[\"DriverNumber\", \"LapTime\"]]\n",
    "auxi['LapTime_ms'] = auxi['LapTime'].astype('timedelta64[ms]')\n",
    "auxi = auxi.groupby([\"DriverNumber\"])[\"LapTime_ms\"].std()\n",
    "auxi = pd.DataFrame(auxi)\n",
    "\n",
    "auxi[\"DriverNumber\"] = auxi.index\n",
    "auxi = auxi.reset_index(drop=True)\n",
    "\n",
    "data = pd.merge(left=data, right=auxi, how='right')\n",
    "data = data.rename(columns = {'LapTime_ms': 'SDLapTime'})\n",
    "    \n",
    "import datetime\n",
    "data['SDLapTime'] = data['SDLapTime'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "# Add average split times variable\n",
    "besttime = pd.DataFrame(aux.groupby(\"LapNumber\")[\"LapTime\"].min())\n",
    "\n",
    "besttime[\"LapNumber\"] = besttime.index\n",
    "besttime  = besttime .reset_index(drop=True)\n",
    "\n",
    "best_lap = besttime.groupby('LapNumber')['LapTime'].min()\n",
    "\n",
    "merged = pd.merge(aux, best_lap, on='LapNumber', suffixes=('', '_best'))\n",
    "\n",
    "merged['diff'] = merged['LapTime'] - merged['LapTime_best']\n",
    "\n",
    "driver_avg_diff = merged.groupby('DriverNumber')['diff'].mean().reset_index()\n",
    "\n",
    "driver_avg_diff = driver_avg_diff.rename(columns={'diff': 'AvgSplitTime'})\n",
    "\n",
    "data = pd.merge(left=data, right=driver_avg_diff, how='right')\n",
    "\n",
    "# Get information about pit stops\n",
    "# Add average pitstop time and number of pit stops\n",
    "pit_stops = pd.read_csv(\"pit_stops.csv\")\n",
    "races = pd.read_csv(\"races.csv\")\n",
    "drivers = pd.read_csv(\"drivers.csv\")\n",
    "\n",
    "listdrivers = np.unique(data[\"Abbreviation\"])\n",
    "\n",
    "filtered_drivers = drivers[drivers['code'].isin(listdrivers)]\n",
    "\n",
    "k = filtered_drivers[\"driverId\"]\n",
    "\n",
    "b = races[(races[\"year\"] == 2020) & (races[\"round\"] == 17)]\n",
    "b = b[\"raceId\"]\n",
    "b = int(b)\n",
    "\n",
    "auxpit = pit_stops[pit_stops[\"driverId\"].isin(k)]\n",
    "auxpit = auxpit[auxpit[\"raceId\"] == b]\n",
    "auxpit = auxpit.drop([\"lap\", \"time\", \"duration\"], axis = 1)\n",
    "\n",
    "merged_df = auxpit.merge(drivers, on='driverId')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df = merged_df.drop([\"raceId\", \"driverId\", \"driverRef\", \"forename\", \"surname\", \"dob\", \"nationality\", \"url\"], axis = 1)\n",
    "\n",
    "transformed_df = merged_df.groupby('code').agg({\n",
    "'milliseconds': 'mean',\n",
    "'stop': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_df)\n",
    "\n",
    "merged_data = data.merge(transformed_df, left_on='Abbreviation', right_on='code', how = \"left\")\n",
    "\n",
    "merged_data = pd.DataFrame(merged_data)\n",
    "merged_data = merged_data.drop(\"code\", axis = 1)\n",
    "\n",
    "mask = merged_data['milliseconds'].notna()\n",
    "merged_data.loc[mask, 'milliseconds'] = merged_data.loc[mask, 'milliseconds'].apply(lambda x: datetime.timedelta(milliseconds=x))\n",
    "\n",
    "merged_data = merged_data.rename(columns = {'milliseconds': 'AvgPitTime', \"stop\": \"PitstopNo\"})\n",
    "\n",
    "# Add number of laps on each type of compound\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "drivers2 = aux['DriverNumber'].unique()\n",
    "compounds = ['SOFT', 'MEDIUM', 'HARD', 'INTERMEDIATE', 'WET']\n",
    "all_combinations = pd.MultiIndex.from_product([drivers2, compounds], names=['DriverNumber', 'Compound'])\n",
    "all_combinations_df = pd.DataFrame(index=all_combinations).reset_index()\n",
    "\n",
    "compound_counts = aux.groupby(['DriverNumber', 'Compound']).size().reset_index(name='Laps')\n",
    "\n",
    "compound_counts = pd.merge(all_combinations_df, compound_counts, on=['DriverNumber', 'Compound'], how='outer').fillna(0)\n",
    "compound_counts_pivot = compound_counts.pivot(index='DriverNumber', columns='Compound', values='Laps').fillna(0)\n",
    "indexi = compound_counts_pivot.index\n",
    "indexi = list(indexi)\n",
    "\n",
    "compound_counts_pivot = compound_counts_pivot.reset_index(level=0, drop=True)\n",
    "compound_counts_pivot[\"DriverNumber\"] = indexi\n",
    "compound_counts_pivot = pd.DataFrame(compound_counts_pivot)\n",
    "\n",
    "merged_data_compound = pd.merge(merged_data, compound_counts_pivot, on='DriverNumber')\n",
    "\n",
    "data = merged_data_compound\n",
    "\n",
    "# Add engine manufacturer for each team\n",
    "engines = pd.read_csv(\"engines2020.csv\", sep = \";\")\n",
    "\n",
    "data = data.merge(engines, left_on='TeamName', right_on='Car', how = \"left\")\n",
    "data = data.drop([\"Car\"], axis = 1)\n",
    "\n",
    "# Get information on number of previous wins at that particular race\n",
    "#wins = pd.read_csv(\"podiums2020.csv\", sep = \";\")\n",
    "#wins = wins[[\"Driver\", \"2\"]]\n",
    "\n",
    "#data = pd.merge(left=data, right=wins , how='right', left_on=\"Abbreviation\", right_on = \"Driver\")\n",
    "\n",
    "#data = data.drop([\"Driver\"], axis = 1)\n",
    "\n",
    "#data = data.rename(columns={'2': 'PrevPodiumRace'})\n",
    "\n",
    "# Get weather data\n",
    "rainy = pd.DataFrame(race_2020.weather_data)\n",
    "\n",
    "counts = rainy['Rainfall'].value_counts()\n",
    "\n",
    "def determine_rain(counts):\n",
    "    if counts.get(False, 0) > counts.get(True, 0):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_rainy = determine_rain(counts)\n",
    "\n",
    "data[\"Rain\"] = is_rainy\n",
    "\n",
    "# Add telemtry variables\n",
    "data.dropna(subset=['DriverNumber'], inplace=True)\n",
    "driversnumbers = np.unique(data[\"DriverNumber\"])\n",
    "\n",
    "agg = pd.DataFrame()\n",
    "for i in driversnumbers:\n",
    "    tele = pd.DataFrame(race_2020.car_data[i])\n",
    "    avg_speed = tele['Speed'].mean()\n",
    "    max_speed = tele['Speed'].max()\n",
    "    avg_rpm = tele['RPM'].mean()\n",
    "    max_rpm = tele['RPM'].max()\n",
    "    avg_throttle = tele['Throttle'].mean()\n",
    "    max_throttle = tele['Throttle'].max()\n",
    "    max_throttle_pct = (tele['Throttle'] == max_throttle).sum() / len(tele) * 100\n",
    "    break_percentage = tele['Brake'].sum() / len(tele) * 100\n",
    "\n",
    "    driver_data = {\n",
    "        'Driver': i,\n",
    "        'AverageSpeed': avg_speed,\n",
    "        'MaxSpeed': max_speed,\n",
    "        'AverageRPM': avg_rpm,\n",
    "        'MaxRPM': max_rpm,\n",
    "        'AverageThrottle': avg_throttle,\n",
    "        'MaxThrottlePct': max_throttle_pct,\n",
    "        'Brake': break_percentage\n",
    "        }\n",
    "    \n",
    "    agg = pd.concat([agg, pd.DataFrame(driver_data, index=[0])], ignore_index=True)\n",
    "\n",
    "data = pd.merge(left=data, right=agg , how='right', left_on=\"DriverNumber\", right_on = \"Driver\")\n",
    "data[\"raceID\"] = \"37\"\n",
    "all_data = pd.concat([all_data, data])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no pit stops\n",
    "all_data['AvgPitTime'] = all_data['AvgPitTime'].fillna(pd.Timedelta(\"0 days\"))\n",
    "\n",
    "all_data['PitstopNo'] = all_data['PitstopNo'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(r'2020data.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5735bfa344102866903967fdbfb95794eb353dada4cd8a6f59858b1fed696402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
