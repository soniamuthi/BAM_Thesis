{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import statsmodels.formula.api as smf\n",
    "from plotly.graph_objects import Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset and do the required pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mergedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"DriverNumber\", \"Driver\", \"Points\"], axis = 1)\n",
    "aux = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"AverageRPM\"], axis = 1)\n",
    "df = df.drop([\"AvgLapTime\"], axis = 1)\n",
    "df = df.drop([\"AvgSplitTime\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns based on Status values\n",
    "df['carIssue'] = (df['Status'] == 'carIssue').astype(int)\n",
    "df['driverIssue'] = (df['Status'] == 'driverIssue').astype(int)\n",
    "df = df.drop('Status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RaceCountry\"] = df[\"RaceCountry\"].str.replace(\" \", \"\")\n",
    "df[\"TeamName\"] = df[\"TeamName\"].str.replace(\" \", \"\")\n",
    "df[\"Engine\"] = df[\"Engine\"].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'df_points.csv', index=True, header=True)\n",
    "#df.to_csv(r'df_position.csv', index=True, header=True)\n",
    "#df.to_csv(r'plotdata_points.csv', index=True, header=True)\n",
    "#df.to_csv(r'plotdata_position.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all categorical variables except \"Abbreviation\" and \"raceCountry\"\n",
    "cat_vars = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_vars.remove(\"Abbreviation\")\n",
    "cat_vars.remove(\"RaceCountry\")\n",
    "\n",
    "# create dummy variables\n",
    "dummies = pd.get_dummies(df[cat_vars], drop_first=True)\n",
    "\n",
    "# drop the original categorical variables from the DataFrame\n",
    "df = df.drop(cat_vars, axis=1)\n",
    "\n",
    "# concatenate the dummy variables with the remaining variables in the DataFrame\n",
    "df = pd.concat([df, dummies], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merf import MERF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two datasets based on the Year column\n",
    "df_before = df[df['Year'].isin([2019, 2020])]\n",
    "df_after = df[df['Year'].isin([2021, 2022])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets based on the raceID column\n",
    "train_df = df_before[(df_before['raceID'] >= 1) & (df_before['raceID'] <= 29)]\n",
    "test_df = df_before[(df_before['raceID'] >= 30) & (df_before['raceID'] <= 37)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Position', axis=1)\n",
    "Y_train = train_df['Position']\n",
    "X_test = test_df.drop('Position', axis=1)\n",
    "Y_test = test_df['Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('RaceCountry', axis=1)\n",
    "X_train = X_train.drop('Year', axis=1)\n",
    "X_test = X_test.drop('RaceCountry', axis=1)\n",
    "X_test = X_test.drop('Year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_train = X_train[['raceID']]\n",
    "clusters_train = X_train['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:307] Training GLL is 2435.012355347997 at iteration 1.\n",
      "INFO     [merf.py:307] Training GLL is 2395.2879496758464 at iteration 2.\n",
      "INFO     [merf.py:307] Training GLL is 2382.0263857090836 at iteration 3.\n",
      "INFO     [merf.py:307] Training GLL is 2372.2077972567336 at iteration 4.\n",
      "INFO     [merf.py:307] Training GLL is 2364.401558292814 at iteration 5.\n",
      "INFO     [merf.py:307] Training GLL is 2358.022992796393 at iteration 6.\n",
      "INFO     [merf.py:307] Training GLL is 2352.725299922297 at iteration 7.\n",
      "INFO     [merf.py:307] Training GLL is 2348.1462431501573 at iteration 8.\n",
      "INFO     [merf.py:307] Training GLL is 2344.130624386462 at iteration 9.\n",
      "INFO     [merf.py:307] Training GLL is 2340.554890117171 at iteration 10.\n",
      "INFO     [merf.py:307] Training GLL is 2337.360798404492 at iteration 11.\n",
      "INFO     [merf.py:307] Training GLL is 2334.452009283764 at iteration 12.\n",
      "INFO     [merf.py:307] Training GLL is 2331.790672118035 at iteration 13.\n",
      "INFO     [merf.py:307] Training GLL is 2329.345620594059 at iteration 14.\n",
      "INFO     [merf.py:307] Training GLL is 2327.0768362513454 at iteration 15.\n",
      "INFO     [merf.py:307] Training GLL is 2324.9666355896957 at iteration 16.\n",
      "INFO     [merf.py:307] Training GLL is 2322.9888614456295 at iteration 17.\n",
      "INFO     [merf.py:307] Training GLL is 2321.132804433961 at iteration 18.\n",
      "INFO     [merf.py:307] Training GLL is 2319.373244564516 at iteration 19.\n",
      "INFO     [merf.py:307] Training GLL is 2317.701078016667 at iteration 20.\n",
      "INFO     [merf.py:307] Training GLL is 2316.124448153598 at iteration 21.\n",
      "INFO     [merf.py:307] Training GLL is 2314.6394910482004 at iteration 22.\n",
      "INFO     [merf.py:307] Training GLL is 2313.207869232837 at iteration 23.\n",
      "INFO     [merf.py:307] Training GLL is 2311.8515404108416 at iteration 24.\n",
      "INFO     [merf.py:307] Training GLL is 2310.5527490229665 at iteration 25.\n",
      "INFO     [merf.py:307] Training GLL is 2309.3104640096744 at iteration 26.\n",
      "INFO     [merf.py:307] Training GLL is 2308.1177602701055 at iteration 27.\n",
      "INFO     [merf.py:307] Training GLL is 2306.967126142727 at iteration 28.\n",
      "INFO     [merf.py:307] Training GLL is 2305.8564872090933 at iteration 29.\n",
      "INFO     [merf.py:307] Training GLL is 2304.7855205620704 at iteration 30.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<merf.merf.MERF at 0x7fbfc5926820>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_model = SVR(kernel='rbf', gamma='scale')\n",
    "\n",
    "mrf = MERF(fixed_effects_model=svr_model, max_iterations=30)\n",
    "mrf.fit(x_train, Z_train, clusters_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mrf.predict(x_train, Z_train, clusters_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 32.5883534311462\n",
      "Test RMSE: 5.708620974556482\n",
      "Test MAE: 4.940584915454136\n",
      "Test R-squared: -0.0006222312438370903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(Y_train, train_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_train, train_preds)\n",
    "r2 = r2_score(Y_train, train_preds)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00028128207952660134"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_values = Y_test\n",
    "predictions = train_preds\n",
    "# Calculate the mean of actual values\n",
    "mean_actual = sum(actual_values) / len(actual_values)\n",
    "\n",
    "# Calculate SSE and SST\n",
    "sse = sum((actual - pred) ** 2 for actual, pred in zip(actual_values, predictions))\n",
    "sst = sum((actual - mean_actual) ** 2 for actual in actual_values)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = 1 - (sse / sst)\n",
    "r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_test.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_test = X_test[['raceID']]\n",
    "clusters_test = X_test['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mrf.predict(x_test, Z_test, clusters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 31.23552633458314\n",
      "Test RMSE: 5.588875229827836\n",
      "Test MAE: 4.825901981369629\n",
      "Test R-squared: 0.0006842910781438283\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets based on the raceID column\n",
    "train_df = df_after[(df_after['raceID'] >= 38) & (df_after['raceID'] <= 72)]\n",
    "test_df = df_after[(df_after['raceID'] >= 73) & (df_after['raceID'] <= 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Position', axis=1)\n",
    "Y_train = train_df['Position']\n",
    "X_test = test_df.drop('Position', axis=1)\n",
    "Y_test = test_df['Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('RaceCountry', axis=1)\n",
    "X_train = X_train.drop('Year', axis=1)\n",
    "X_test = X_test.drop('RaceCountry', axis=1)\n",
    "X_test = X_test.drop('Year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_train = X_train[['raceID']]\n",
    "clusters_train = X_train['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:307] Training GLL is 2698.3374904130565 at iteration 1.\n",
      "INFO     [merf.py:307] Training GLL is 2666.032114070161 at iteration 2.\n",
      "INFO     [merf.py:307] Training GLL is 2660.537947490707 at iteration 3.\n",
      "INFO     [merf.py:307] Training GLL is 2655.6251547166144 at iteration 4.\n",
      "INFO     [merf.py:307] Training GLL is 2651.2173845561233 at iteration 5.\n",
      "INFO     [merf.py:307] Training GLL is 2647.2953006595058 at iteration 6.\n",
      "INFO     [merf.py:307] Training GLL is 2643.741791912943 at iteration 7.\n",
      "INFO     [merf.py:307] Training GLL is 2640.5278139988404 at iteration 8.\n",
      "INFO     [merf.py:307] Training GLL is 2637.577168035475 at iteration 9.\n",
      "INFO     [merf.py:307] Training GLL is 2634.8414779653212 at iteration 10.\n",
      "INFO     [merf.py:307] Training GLL is 2632.303225669452 at iteration 11.\n",
      "INFO     [merf.py:307] Training GLL is 2629.934668593295 at iteration 12.\n",
      "INFO     [merf.py:307] Training GLL is 2627.719330425508 at iteration 13.\n",
      "INFO     [merf.py:307] Training GLL is 2625.6339940048765 at iteration 14.\n",
      "INFO     [merf.py:307] Training GLL is 2623.65801092461 at iteration 15.\n",
      "INFO     [merf.py:307] Training GLL is 2621.786818567886 at iteration 16.\n",
      "INFO     [merf.py:307] Training GLL is 2620.011765750114 at iteration 17.\n",
      "INFO     [merf.py:307] Training GLL is 2618.3232314255956 at iteration 18.\n",
      "INFO     [merf.py:307] Training GLL is 2616.7116835187167 at iteration 19.\n",
      "INFO     [merf.py:307] Training GLL is 2615.1669044586474 at iteration 20.\n",
      "INFO     [merf.py:307] Training GLL is 2613.6860608379825 at iteration 21.\n",
      "INFO     [merf.py:307] Training GLL is 2612.2647696375916 at iteration 22.\n",
      "INFO     [merf.py:307] Training GLL is 2610.8983698686793 at iteration 23.\n",
      "INFO     [merf.py:307] Training GLL is 2609.5832948184525 at iteration 24.\n",
      "INFO     [merf.py:307] Training GLL is 2608.318057247619 at iteration 25.\n",
      "INFO     [merf.py:307] Training GLL is 2607.097627374616 at iteration 26.\n",
      "INFO     [merf.py:307] Training GLL is 2605.9157552913784 at iteration 27.\n",
      "INFO     [merf.py:307] Training GLL is 2604.7670641013233 at iteration 28.\n",
      "INFO     [merf.py:307] Training GLL is 2603.6611894894163 at iteration 29.\n",
      "INFO     [merf.py:307] Training GLL is 2602.589094208334 at iteration 30.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<merf.merf.MERF at 0x7fbfc5926820>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrf.fit(x_train, Z_train, clusters_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mrf.predict(x_train, Z_train, clusters_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 31.564983546760896\n",
      "Test RMSE: 5.618272291973832\n",
      "Test MAE: 4.850067647381201\n",
      "Test R-squared: 0.0012309089697312148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(Y_train, train_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_train, train_preds)\n",
    "r2 = r2_score(Y_train, train_preds)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_test.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_test = X_test[['raceID']]\n",
    "clusters_test = X_test['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mrf.predict(x_test, Z_test, clusters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 31.555037790631737\n",
      "Test RMSE: 5.617387096384914\n",
      "Test MAE: 4.853123115063056\n",
      "Test R-squared: 7.414877490208305e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5735bfa344102866903967fdbfb95794eb353dada4cd8a6f59858b1fed696402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
