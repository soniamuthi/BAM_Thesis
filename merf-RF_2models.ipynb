{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import statsmodels.formula.api as smf\n",
    "from plotly.graph_objects import Layout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset and do the required pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mergedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abbreviation', 'DriverNumber', 'TeamName', 'Position', 'GridPosition',\n",
       "       'Status', 'Points', 'RaceCountry', 'Year', 'AgeAtGP', 'BestQualiTime',\n",
       "       'FLap', 'AvgLapTime', 'SDLapTime', 'AvgSplitTime', 'AvgPitTime',\n",
       "       'PitstopNo', 'HARD', 'INTERMEDIATE', 'MEDIUM', 'SOFT', 'WET', 'Engine',\n",
       "       'Rain', 'Driver', 'AverageSpeed', 'MaxSpeed', 'AverageRPM', 'MaxRPM',\n",
       "       'AverageThrottle', 'MaxThrottlePct', 'Brake', 'raceID', 'CircuitType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"DriverNumber\", \"Driver\", \"Points\"], axis = 1)\n",
    "aux = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns based on Status values\n",
    "df['carIssue'] = (df['Status'] == 'carIssue').astype(int)\n",
    "df['driverIssue'] = (df['Status'] == 'driverIssue').astype(int)\n",
    "df = df.drop('Status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"AverageRPM\"], axis = 1)\n",
    "df = df.drop([\"AvgLapTime\"], axis = 1)\n",
    "df = df.drop([\"AvgSplitTime\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RaceCountry\"] = df[\"RaceCountry\"].str.replace(\" \", \"\")\n",
    "df[\"TeamName\"] = df[\"TeamName\"].str.replace(\" \", \"\")\n",
    "df[\"Engine\"] = df[\"Engine\"].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'df_points.csv', index=True, header=True)\n",
    "#df.to_csv(r'df_position.csv', index=True, header=True)\n",
    "#df.to_csv(r'plotdata_points.csv', index=True, header=True)\n",
    "#df.to_csv(r'plotdata_position.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all categorical variables except \"Abbreviation\" and \"raceCountry\"\n",
    "cat_vars = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_vars.remove(\"Abbreviation\")\n",
    "cat_vars.remove(\"RaceCountry\")\n",
    "\n",
    "# create dummy variables\n",
    "dummies = pd.get_dummies(df[cat_vars], drop_first=True)\n",
    "\n",
    "# drop the original categorical variables from the DataFrame\n",
    "df = df.drop(cat_vars, axis=1)\n",
    "\n",
    "# concatenate the dummy variables with the remaining variables in the DataFrame\n",
    "df = pd.concat([df, dummies], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merf import MERF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two datasets based on the Year column\n",
    "df_before = df[df['Year'].isin([2019, 2020])]\n",
    "df_after = df[df['Year'].isin([2021, 2022])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets based on the raceID column\n",
    "train_df = df_before[(df_before['raceID'] >= 1) & (df_before['raceID'] <= 29)]\n",
    "test_df = df_before[(df_before['raceID'] >= 30) & (df_before['raceID'] <= 37)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Position', axis=1)\n",
    "Y_train = train_df['Position']\n",
    "X_test = test_df.drop('Position', axis=1)\n",
    "Y_test = test_df['Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('RaceCountry', axis=1)\n",
    "X_train = X_train.drop('Year', axis=1)\n",
    "X_test = X_test.drop('RaceCountry', axis=1)\n",
    "X_test = X_test.drop('Year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_train = X_train[['raceID']]\n",
    "clusters_train = X_train['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:307] Training GLL is 1667.7207546822453 at iteration 1.\n",
      "INFO     [merf.py:307] Training GLL is 1644.492180628175 at iteration 2.\n",
      "INFO     [merf.py:307] Training GLL is 1641.503739236482 at iteration 3.\n",
      "INFO     [merf.py:307] Training GLL is 1643.1927281405087 at iteration 4.\n",
      "INFO     [merf.py:307] Training GLL is 1634.7337215036828 at iteration 5.\n",
      "INFO     [merf.py:307] Training GLL is 1633.29006564651 at iteration 6.\n",
      "INFO     [merf.py:307] Training GLL is 1630.438688044807 at iteration 7.\n",
      "INFO     [merf.py:307] Training GLL is 1634.1952936398025 at iteration 8.\n",
      "INFO     [merf.py:307] Training GLL is 1626.253326111924 at iteration 9.\n",
      "INFO     [merf.py:307] Training GLL is 1626.6359900715845 at iteration 10.\n",
      "INFO     [merf.py:307] Training GLL is 1623.7718507618831 at iteration 11.\n",
      "INFO     [merf.py:307] Training GLL is 1622.434981957772 at iteration 12.\n",
      "INFO     [merf.py:307] Training GLL is 1626.2529652467033 at iteration 13.\n",
      "INFO     [merf.py:307] Training GLL is 1626.4479716455996 at iteration 14.\n",
      "INFO     [merf.py:307] Training GLL is 1621.9375813662352 at iteration 15.\n",
      "INFO     [merf.py:307] Training GLL is 1622.9348406770475 at iteration 16.\n",
      "INFO     [merf.py:307] Training GLL is 1619.9159086638413 at iteration 17.\n",
      "INFO     [merf.py:307] Training GLL is 1624.0641444107368 at iteration 18.\n",
      "INFO     [merf.py:307] Training GLL is 1623.894330042789 at iteration 19.\n",
      "INFO     [merf.py:307] Training GLL is 1614.9086650220731 at iteration 20.\n",
      "INFO     [merf.py:307] Training GLL is 1619.712128888567 at iteration 21.\n",
      "INFO     [merf.py:307] Training GLL is 1619.5983965423288 at iteration 22.\n",
      "INFO     [merf.py:307] Training GLL is 1624.9820300986814 at iteration 23.\n",
      "INFO     [merf.py:307] Training GLL is 1620.0346659309098 at iteration 24.\n",
      "INFO     [merf.py:307] Training GLL is 1622.0327563923056 at iteration 25.\n",
      "INFO     [merf.py:307] Training GLL is 1622.484688088504 at iteration 26.\n",
      "INFO     [merf.py:307] Training GLL is 1620.2065583419885 at iteration 27.\n",
      "INFO     [merf.py:307] Training GLL is 1622.0459771845985 at iteration 28.\n",
      "INFO     [merf.py:307] Training GLL is 1619.8476729658648 at iteration 29.\n",
      "INFO     [merf.py:307] Training GLL is 1622.6732862341455 at iteration 30.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<merf.merf.MERF at 0x7f9333ea76d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mrf = MERF(fixed_effects_model=RandomForestRegressor(max_depth = 3), max_iterations=30)\n",
    "#mrf = MERF(max_iterations=30)\n",
    "#mrf = MERF(fixed_effects_model = LinearRegression(), max_iterations=30)\n",
    "mrf.fit(x_train, Z_train, clusters_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mrf.predict(x_train, Z_train, clusters_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 8.93061313801887\n",
      "Test RMSE: 2.9884131471432913\n",
      "Test MAE: 2.32267877166\n",
      "Test R-squared: 0.7257863898088434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(Y_train, train_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_train, train_preds)\n",
    "r2 = r2_score(Y_train, train_preds)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_test.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_test = X_test[['raceID']]\n",
    "clusters_test = X_test['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mrf.predict(x_test, Z_test, clusters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 12.08399345924616\n",
      "Test RMSE: 3.476203886317107\n",
      "Test MAE: 2.809712983421306\n",
      "Test R-squared: 0.6133977586616259\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets based on the raceID column\n",
    "train_df = df_after[(df_after['raceID'] >= 38) & (df_after['raceID'] <= 72)]\n",
    "test_df = df_after[(df_after['raceID'] >= 73) & (df_after['raceID'] <= 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Position', axis=1)\n",
    "Y_train = train_df['Position']\n",
    "X_test = test_df.drop('Position', axis=1)\n",
    "Y_test = test_df['Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('RaceCountry', axis=1)\n",
    "X_train = X_train.drop('Year', axis=1)\n",
    "X_test = X_test.drop('RaceCountry', axis=1)\n",
    "X_test = X_test.drop('Year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_train = X_train[['raceID']]\n",
    "clusters_train = X_train['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:307] Training GLL is 1943.336622875812 at iteration 1.\n",
      "INFO     [merf.py:307] Training GLL is 1918.5978471651279 at iteration 2.\n",
      "INFO     [merf.py:307] Training GLL is 1912.228048140183 at iteration 3.\n",
      "INFO     [merf.py:307] Training GLL is 1907.9358149604664 at iteration 4.\n",
      "INFO     [merf.py:307] Training GLL is 1903.4509125730285 at iteration 5.\n",
      "INFO     [merf.py:307] Training GLL is 1902.0050403753103 at iteration 6.\n",
      "INFO     [merf.py:307] Training GLL is 1894.5348328439893 at iteration 7.\n",
      "INFO     [merf.py:307] Training GLL is 1893.032564766561 at iteration 8.\n",
      "INFO     [merf.py:307] Training GLL is 1894.5779495112515 at iteration 9.\n",
      "INFO     [merf.py:307] Training GLL is 1890.091034926103 at iteration 10.\n",
      "INFO     [merf.py:307] Training GLL is 1888.1100596779393 at iteration 11.\n",
      "INFO     [merf.py:307] Training GLL is 1880.865080873833 at iteration 12.\n",
      "INFO     [merf.py:307] Training GLL is 1885.0335846085184 at iteration 13.\n",
      "INFO     [merf.py:307] Training GLL is 1877.833837993539 at iteration 14.\n",
      "INFO     [merf.py:307] Training GLL is 1878.3237064949749 at iteration 15.\n",
      "INFO     [merf.py:307] Training GLL is 1869.948815285588 at iteration 16.\n",
      "INFO     [merf.py:307] Training GLL is 1880.356558153718 at iteration 17.\n",
      "INFO     [merf.py:307] Training GLL is 1874.5770159930207 at iteration 18.\n",
      "INFO     [merf.py:307] Training GLL is 1870.9690731424869 at iteration 19.\n",
      "INFO     [merf.py:307] Training GLL is 1871.8244756559975 at iteration 20.\n",
      "INFO     [merf.py:307] Training GLL is 1863.995629818622 at iteration 21.\n",
      "INFO     [merf.py:307] Training GLL is 1868.3490599342888 at iteration 22.\n",
      "INFO     [merf.py:307] Training GLL is 1864.2686477174864 at iteration 23.\n",
      "INFO     [merf.py:307] Training GLL is 1861.8366018788847 at iteration 24.\n",
      "INFO     [merf.py:307] Training GLL is 1863.12236404808 at iteration 25.\n",
      "INFO     [merf.py:307] Training GLL is 1867.094498060801 at iteration 26.\n",
      "INFO     [merf.py:307] Training GLL is 1868.158780267359 at iteration 27.\n",
      "INFO     [merf.py:307] Training GLL is 1864.6129271482687 at iteration 28.\n",
      "INFO     [merf.py:307] Training GLL is 1859.1750089277348 at iteration 29.\n",
      "INFO     [merf.py:307] Training GLL is 1856.4850779396488 at iteration 30.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<merf.merf.MERF at 0x7f9333ea76d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mrf.fit(x_train, Z_train, clusters_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = mrf.predict(x_train, Z_train, clusters_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 10.198891307305878\n",
      "Test RMSE: 3.1935703072432706\n",
      "Test MAE: 2.4295741487177502\n",
      "Test R-squared: 0.6772899505737366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(Y_train, train_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_train, train_preds)\n",
    "r2 = r2_score(Y_train, train_preds)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_test.drop(['Abbreviation', 'raceID'], axis = 1)\n",
    "Z_test = X_test[['raceID']]\n",
    "clusters_test = X_test['raceID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mrf.predict(x_test, Z_test, clusters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 8.893606771940293\n",
      "Test RMSE: 2.9822150780821115\n",
      "Test MAE: 2.3635600126175174\n",
      "Test R-squared: 0.7181766226712019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE:\", mae)\n",
    "print(\"Test R-squared:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5735bfa344102866903967fdbfb95794eb353dada4cd8a6f59858b1fed696402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
